{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNbBw679t6E7UA2N0KgNbvO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"id":"gEgncQ4tMxIa","outputId":"14ebc2e7-f35b-41fd-a772-9f83fbd60ba0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Bibliotecas carregadas!\n","Estrutura de pastas criada!\n","Suba suas 40 imagens de COPOS\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-38a924f4-fa30-4cbd-a2e5-d2624039c36c\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-38a924f4-fa30-4cbd-a2e5-d2624039c36c\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving copo (1).jpg to copo (1).jpg\n","Saving copo (2).jpg to copo (2).jpg\n","Saving copo (3).jpg to copo (3).jpg\n","Saving copo (4).jpg to copo (4).jpg\n","Saving copo (5).jpg to copo (5).jpg\n","Saving copo (6).jpg to copo (6).jpg\n","Saving copo (7).jpg to copo (7).jpg\n","Saving copo (8).jpg to copo (8).jpg\n","Saving copo (9).jpg to copo (9).jpg\n","Saving copo (10).jpg to copo (10).jpg\n","Saving copo (11).jpg to copo (11).jpg\n","Saving copo (12).jpg to copo (12).jpg\n","Saving copo (13).jpg to copo (13).jpg\n","Saving copo (14).jpg to copo (14).jpg\n","Saving copo (15).jpg to copo (15).jpg\n","Saving copo (16).jpg to copo (16).jpg\n","Saving copo (17).jpg to copo (17).jpg\n","Saving copo (18).jpg to copo (18).jpg\n","Saving copo (19).jpg to copo (19).jpg\n","Saving copo (20).jpg to copo (20).jpg\n","Saving copo (21).jpg to copo (21).jpg\n","Saving copo (22).jpg to copo (22).jpg\n","Saving copo (23).jpg to copo (23).jpg\n","Saving copo (24).jpg to copo (24).jpg\n","Saving copo (25).jpg to copo (25).jpg\n","Saving copo (26).jpg to copo (26).jpg\n","Saving copo (27).jpg to copo (27).jpg\n","Saving copo (28).jpg to copo (28).jpg\n","Saving copo (29).jpg to copo (29).jpg\n","Saving copo (30).jpg to copo (30).jpg\n","Saving copo (31).jpg to copo (31).jpg\n","Saving copo (32).jpg to copo (32).jpg\n","Saving copo (33).jpg to copo (33).jpg\n","Saving copo (34).jpg to copo (34).jpg\n","Saving copo (35).jpg to copo (35).jpg\n","Saving copo (36).jpg to copo (36).jpg\n","Saving copo (37).jpg to copo (37).jpg\n","Saving copo (38).jpg to copo (38).jpg\n","Saving copo (39).jpg to copo (39).jpg\n","Saving copo (40).jpg to copo (40).jpg\n","Suba suas 40 imagens de GARRAFAS\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-55cb2817-ae74-4502-bbb9-8fab66467642\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-55cb2817-ae74-4502-bbb9-8fab66467642\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving garrafa (1).jpeg to garrafa (1).jpeg\n","Saving garrafa (2).jpeg to garrafa (2).jpeg\n","Saving garrafa (3).jpg to garrafa (3).jpg\n","Saving garrafa (4).jpg to garrafa (4).jpg\n","Saving garrafa (5).jpg to garrafa (5).jpg\n","Saving garrafa (6).jpg to garrafa (6).jpg\n","Saving garrafa (7).jpg to garrafa (7).jpg\n","Saving garrafa (8).jpg to garrafa (8).jpg\n","Saving garrafa (9).jpg to garrafa (9).jpg\n","Saving garrafa (10).jpg to garrafa (10).jpg\n","Saving garrafa (11).jpg to garrafa (11).jpg\n","Saving garrafa (12).jpg to garrafa (12).jpg\n","Saving garrafa (13).jpg to garrafa (13).jpg\n","Saving garrafa (14).jpg to garrafa (14).jpg\n","Saving garrafa (15).jpg to garrafa (15).jpg\n","Saving garrafa (16).jpg to garrafa (16).jpg\n","Saving garrafa (17).jpg to garrafa (17).jpg\n","Saving garrafa (18).jpg to garrafa (18).jpg\n","Saving garrafa (19).jpg to garrafa (19).jpg\n","Saving garrafa (20).jpg to garrafa (20).jpg\n","Saving garrafa (21).jpg to garrafa (21).jpg\n","Saving garrafa (22).jpg to garrafa (22).jpg\n","Saving garrafa (23).jpg to garrafa (23).jpg\n","Saving garrafa (24).jpg to garrafa (24).jpg\n","Saving garrafa (25).jpg to garrafa (25).jpg\n","Saving garrafa (26).jpg to garrafa (26).jpg\n","Saving garrafa (27).jpg to garrafa (27).jpg\n","Saving garrafa (28).jpg to garrafa (28).jpg\n","Saving garrafa (29).jpg to garrafa (29).jpg\n","Saving garrafa (30).jpg to garrafa (30).jpg\n","Saving garrafa (31).jpg to garrafa (31).jpg\n","Saving garrafa (32).jpg to garrafa (32).jpg\n","Saving garrafa (33).jpg to garrafa (33).jpg\n","Saving garrafa (34).jpg to garrafa (34).jpg\n","Saving garrafa (35).jpg to garrafa (35).jpg\n","Saving garrafa (36).jpg to garrafa (36).jpg\n","Saving garrafa (37).jpg to garrafa (37).jpg\n","Saving garrafa (38).jpg to garrafa (38).jpg\n","Saving garrafa (39).png to garrafa (39).png\n","Saving garrafa (40).jpg to garrafa (40).jpg\n","Suba os arquivos .TXT de COPOS\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-c98de4c5-c707-4327-9199-b9b09d20ca17\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-c98de4c5-c707-4327-9199-b9b09d20ca17\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving copo (1).txt to copo (1).txt\n","Saving copo (2).txt to copo (2).txt\n","Saving copo (3).txt to copo (3).txt\n","Saving copo (4).txt to copo (4).txt\n","Saving copo (5).txt to copo (5).txt\n","Saving copo (6).txt to copo (6).txt\n","Saving copo (7).txt to copo (7).txt\n","Saving copo (8).txt to copo (8).txt\n","Saving copo (9).txt to copo (9).txt\n","Saving copo (10).txt to copo (10).txt\n","Saving copo (11).txt to copo (11).txt\n","Saving copo (12).txt to copo (12).txt\n","Saving copo (13).txt to copo (13).txt\n","Saving copo (14).txt to copo (14).txt\n","Saving copo (15).txt to copo (15).txt\n","Saving copo (16).txt to copo (16).txt\n","Saving copo (17).txt to copo (17).txt\n","Saving copo (18).txt to copo (18).txt\n","Saving copo (19).txt to copo (19).txt\n","Saving copo (20).txt to copo (20).txt\n","Saving copo (21).txt to copo (21).txt\n","Saving copo (22).txt to copo (22).txt\n","Saving copo (23).txt to copo (23).txt\n","Saving copo (24).txt to copo (24).txt\n","Saving copo (25).txt to copo (25).txt\n","Saving copo (26).txt to copo (26).txt\n","Saving copo (27).txt to copo (27).txt\n","Saving copo (28).txt to copo (28).txt\n","Saving copo (29).txt to copo (29).txt\n","Saving copo (30).txt to copo (30).txt\n","Saving copo (31).txt to copo (31).txt\n","Saving copo (32).txt to copo (32).txt\n","Saving copo (33).txt to copo (33).txt\n","Saving copo (34).txt to copo (34).txt\n","Saving copo (35).txt to copo (35).txt\n","Saving copo (36).txt to copo (36).txt\n","Saving copo (37).txt to copo (37).txt\n","Saving copo (38).txt to copo (38).txt\n","Saving copo (39).txt to copo (39).txt\n","Saving copo (40).txt to copo (40).txt\n","Suba os arquivos .TXT de GARRAFAS\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-a644bc12-78b7-4438-81aa-c89d02aa3f4a\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-a644bc12-78b7-4438-81aa-c89d02aa3f4a\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving garrafa (1).txt to garrafa (1).txt\n","Saving garrafa (2).txt to garrafa (2).txt\n","Saving garrafa (3).txt to garrafa (3).txt\n","Saving garrafa (6).txt to garrafa (6).txt\n","Saving garrafa (7).txt to garrafa (7).txt\n","Saving garrafa (8).txt to garrafa (8).txt\n","Saving garrafa (9).txt to garrafa (9).txt\n","Saving garrafa (10).txt to garrafa (10).txt\n","Saving garrafa (11).txt to garrafa (11).txt\n","Saving garrafa (12).txt to garrafa (12).txt\n","Saving garrafa (13).txt to garrafa (13).txt\n","Saving garrafa (14).txt to garrafa (14).txt\n","Saving garrafa (15).txt to garrafa (15).txt\n","Saving garrafa (16).txt to garrafa (16).txt\n","Saving garrafa (17).txt to garrafa (17).txt\n","Saving garrafa (18).txt to garrafa (18).txt\n","Saving garrafa (19).txt to garrafa (19).txt\n","Saving garrafa (20).txt to garrafa (20).txt\n","Saving garrafa (21).txt to garrafa (21).txt\n","Saving garrafa (22).txt to garrafa (22).txt\n","Saving garrafa (23).txt to garrafa (23).txt\n","Saving garrafa (24).txt to garrafa (24).txt\n","Saving garrafa (25).txt to garrafa (25).txt\n","Saving garrafa (26).txt to garrafa (26).txt\n","Saving garrafa (27).txt to garrafa (27).txt\n","Saving garrafa (28).txt to garrafa (28).txt\n","Saving garrafa (29).txt to garrafa (29).txt\n","Saving garrafa (30).txt to garrafa (30).txt\n","Saving garrafa (31).txt to garrafa (31).txt\n","Saving garrafa (32).txt to garrafa (32).txt\n","Saving garrafa (33).txt to garrafa (33).txt\n","Saving garrafa (34).txt to garrafa (34).txt\n","Saving garrafa (35).txt to garrafa (35).txt\n","Saving garrafa (36).txt to garrafa (36).txt\n","Saving garrafa (37).txt to garrafa (37).txt\n","Saving garrafas 2 (1).txt to garrafas 2 (1).txt\n","Saving garrafas 2 (2).txt to garrafas 2 (2).txt\n","Saving garrafas 2 (3).txt to garrafas 2 (3).txt\n","Saving garrafas 2 (4).txt to garrafas 2 (4).txt\n","Saving garrafas 2 (5).txt to garrafas 2 (5).txt\n","Dataset dividido em treino, val e teste!\n","Pastas reorganizadas para CNN!\n","fatal: destination path 'yolov5' already exists and is not an empty directory.\n","/content/yolov5\n","Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (3.1.45)\n","Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (3.10.0)\n","Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (2.0.2)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (4.12.0.88)\n","Requirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (11.3.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (6.0.3)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (2.32.4)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (1.16.2)\n","Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (0.1.1.post2209072238)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (2.8.0+cu126)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (0.23.0+cu126)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (4.67.1)\n","Requirement already satisfied: ultralytics>=8.2.64 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 18)) (8.3.214)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 27)) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 28)) (0.13.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 42)) (25.0)\n","Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 43)) (75.2.0)\n","Requirement already satisfied: urllib3>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 51)) (2.5.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.12)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.9)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.2.5)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.9.0.post0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2025.10.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.15.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.4.0)\n","Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics>=8.2.64->-r requirements.txt (line 18)) (1.25.2)\n","Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics>=8.2.64->-r requirements.txt (line 18)) (2.0.17)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (3.0.3)\n","/content\n","Arquivo data.yaml criado!\n","/content/yolov5\n","\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n","2025-10-15 02:01:19.723857: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1760493679.787943   27433 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1760493679.808991   27433 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1760493679.851101   27433 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1760493679.851165   27433 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1760493679.851171   27433 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1760493679.851175   27433 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n","\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=../data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=30, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp_30ep, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 v7.0-440-gf5ebc52c Python-3.12.12 torch-2.8.0+cu126 CPU\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Overriding model.yaml nc=80 with nc=2\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model summary: 214 layers, 7025023 parameters, 7025023 gradients, 16.0 GFLOPs\n","\n","Transferred 343/349 items from yolov5s.pt\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0m1 validation error for InitSchema\n","size\n","  Field required [type=missing, input_value={'scale': (0.8, 1.0), 'ra...: None, 'strict': False}, input_type=dict]\n","    For further information visit https://errors.pydantic.dev/2.11/v/missing\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/FarmTech_Fase6/labels/train/copo... 2 images, 72 backgrounds, 0 corrupt: 100% 74/74 [00:00<00:00, 1137.81it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/FarmTech_Fase6/labels/train/copo.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/FarmTech_Fase6/labels/val/copo... 0 images, 16 backgrounds, 0 corrupt: 100% 16/16 [00:00<00:00, 212.13it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ No labels found in /content/FarmTech_Fase6/labels/val/copo.cache. See https://docs.ultralytics.com/yolov5/tutorials/train_custom_data\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/FarmTech_Fase6/labels/val/copo.cache\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.50 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n","Plotting labels to runs/train/exp_30ep2/labels.jpg... \n","/content/yolov5/train.py:357: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = torch.cuda.amp.GradScaler(enabled=amp)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/exp_30ep2\u001b[0m\n","Starting training for 30 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","  0% 0/5 [00:00<?, ?it/s]/content/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","       0/29         0G     0.1351    0.02378    0.03278          4        640:  20% 1/5 [01:31<06:07, 91.77s/it]/content/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","       0/29         0G    0.06755    0.02343    0.01639          0        640:  40% 2/5 [02:05<02:52, 57.52s/it]/content/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","       0/29         0G    0.07216    0.02326    0.01795          1        640:  60% 3/5 [02:36<01:31, 45.59s/it]/content/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","       0/29         0G    0.06345    0.02317    0.01627          2        640:  80% 4/5 [03:08<00:40, 40.01s/it]/content/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","       0/29         0G    0.05707    0.02305    0.01492          1        640: 100% 5/5 [03:29<00:00, 41.82s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/1 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 1.300s exceeded\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:12<00:00, 12.69s/it]\n","                   all         16          0          0          0          0          0\n","WARNING ⚠️ no labels found in val set, can not compute metrics without labels\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","  0% 0/5 [00:00<?, ?it/s]/content/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","       1/29         0G          0    0.02184          0          0        640:  20% 1/5 [00:27<01:51, 28.00s/it]/content/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","       1/29         0G          0    0.02157          0          0        640:  40% 2/5 [00:57<01:27, 29.16s/it]/content/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","       1/29         0G    0.02663    0.02143   0.006856          2        640:  60% 3/5 [01:30<01:01, 30.65s/it]/content/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","       1/29         0G    0.03988    0.02141     0.0111          4        640:  80% 4/5 [02:00<00:30, 30.60s/it]/content/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","       1/29         0G    0.03191    0.02107   0.008883          0        640: 100% 5/5 [02:21<00:00, 28.33s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/1 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 1.300s exceeded\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:16<00:00, 16.16s/it]\n","                   all         16          0          0          0          0          0\n","WARNING ⚠️ no labels found in val set, can not compute metrics without labels\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","  0% 0/5 [00:00<?, ?it/s]/content/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","       2/29         0G    0.07825    0.01981    0.01715          3        640:  20% 1/5 [00:29<01:58, 29.68s/it]/content/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","       2/29         0G    0.05288    0.01944    0.01279          1        640:  40% 2/5 [01:00<01:30, 30.09s/it]/content/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","       2/29         0G    0.05818    0.01922    0.01689          2        640:  60% 3/5 [01:30<01:00, 30.12s/it]/content/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","       2/29         0G    0.06158      0.019    0.01775          2        640:  80% 4/5 [02:02<00:31, 31.03s/it]/content/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","       2/29         0G     0.0664    0.01869    0.01659          1        640: 100% 5/5 [02:22<00:00, 28.58s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/1 [00:00<?, ?it/s]"]}],"source":["# ===============================\n","# 0️⃣ Importações e Preparação\n","# ===============================\n","import os\n","import random\n","import shutil\n","from google.colab import files\n","from IPython.display import Image, display\n","import glob\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","print(\"Bibliotecas carregadas!\")\n","\n","# Pasta base\n","base_path = '/content/FarmTech_Fase6'\n","folders = [\n","    'images/train','images/val','images/test',\n","    'labels/train','labels/val','labels/test'\n","]\n","for folder in folders:\n","    os.makedirs(os.path.join(base_path, folder), exist_ok=True)\n","print(\"Estrutura de pastas criada!\")\n","\n","# ===============================\n","# 1️⃣ Upload Imagens e Labels\n","# ===============================\n","def upload_files(msg):\n","    print(msg)\n","    uploaded = files.upload()\n","    return list(uploaded.keys())\n","\n","# Upload das imagens\n","copos_imgs = upload_files(\"Suba suas 40 imagens de COPOS\")\n","garrafas_imgs = upload_files(\"Suba suas 40 imagens de GARRAFAS\")\n","\n","# Upload dos labels .txt\n","copos_lbls = upload_files(\"Suba os arquivos .TXT de COPOS\")\n","garrafas_lbls = upload_files(\"Suba os arquivos .TXT de GARRAFAS\")\n","\n","# ===============================\n","# 2️⃣ Organizar dataset (train/val/test)\n","# ===============================\n","def split_and_move(files_list, labels_list, class_name):\n","    combined = list(zip(files_list, labels_list))\n","    random.shuffle(combined)\n","    files_list, labels_list = zip(*combined)\n","\n","    train_files = files_list[:32]\n","    val_files = files_list[32:36]\n","    test_files = files_list[36:40]\n","\n","    train_labels = labels_list[:32]\n","    val_labels = labels_list[32:36]\n","    test_labels = labels_list[36:40]\n","\n","    def move(files, labels, img_folder, lbl_folder):\n","        for f,l in zip(files,labels):\n","            shutil.move(f, os.path.join(img_folder, f))\n","            shutil.move(l, os.path.join(lbl_folder, l))\n","\n","    move(train_files, train_labels, os.path.join(base_path,'images/train'), os.path.join(base_path,'labels/train'))\n","    move(val_files, val_labels, os.path.join(base_path,'images/val'), os.path.join(base_path,'labels/val'))\n","    move(test_files, test_labels, os.path.join(base_path,'images/test'), os.path.join(base_path,'labels/test'))\n","\n","# Organizar copos e garrafas\n","split_and_move(copos_imgs, copos_lbls, 'copo')\n","split_and_move(garrafas_imgs, garrafas_lbls, 'garrafa')\n","print(\"Dataset dividido em treino, val e teste!\")\n","\n","# ===============================\n","# 3️⃣ Reorganizar para CNN\n","# ===============================\n","base_img = '/content/FarmTech_Fase6/images'\n","classes = ['copo','garrafa']\n","\n","def reorganize_for_cnn(split):\n","    img_path = os.path.join(base_img, split)\n","    for cls in classes:\n","        cls_folder = os.path.join(img_path, cls)\n","        os.makedirs(cls_folder, exist_ok=True)\n","    # mover imagens\n","    for f in os.listdir(img_path):\n","        if f.lower().endswith('.jpg'):\n","            moved = False\n","            for cls in classes:\n","                if cls in f.lower():\n","                    shutil.move(os.path.join(img_path,f), os.path.join(img_path,cls,f))\n","                    moved = True\n","                    break\n","            if not moved:\n","                print(f\"Atenção: não foi possível identificar classe da imagem {f}\")\n","\n","for split in ['train','val','test']:\n","    reorganize_for_cnn(split)\n","print(\"Pastas reorganizadas para CNN!\")\n","\n","# ===============================\n","# 4️⃣ Instalar YOLOv5\n","# ===============================\n","!git clone https://github.com/ultralytics/yolov5.git\n","%cd yolov5\n","!pip install -r requirements.txt\n","%cd ..\n","\n","# ===============================\n","# 5️⃣ Criar data.yaml para YOLOv5\n","# ===============================\n","data_yaml = f\"\"\"\n","train: /content/FarmTech_Fase6/images/train\n","val: /content/FarmTech_Fase6/images/val\n","test: /content/FarmTech_Fase6/images/test\n","\n","nc: 2\n","names: ['copo','garrafa']\n","\"\"\"\n","\n","with open('data.yaml','w') as f:\n","    f.write(data_yaml)\n","print(\"Arquivo data.yaml criado!\")\n","\n","# ===============================\n","# 6️⃣ Treinar YOLOv5\n","# ===============================\n","%cd yolov5\n","!python train.py --img 640 --batch 16 --epochs 30 --data ../data.yaml --weights yolov5s.pt --project runs/train --name exp_30ep\n","!python train.py --img 640 --batch 16 --epochs 60 --data ../data.yaml --weights yolov5s.pt --project runs/train --name exp_60ep\n","%cd ..\n","\n","# ===============================\n","# 7️⃣ Inferência YOLOv5\n","# ===============================\n","!python yolov5/detect.py --weights yolov5/runs/train/exp_30ep/weights/best.pt --source /content/FarmTech_Fase6/images/test --save-txt --project yolov5/runs/detect --name test_exp_30\n","!python yolov5/detect.py --weights yolov5/runs/train/exp_60ep/weights/best.pt --source /content/FarmTech_Fase6/images/test --save-txt --project yolov5/runs/detect --name test_exp_60\n","\n","# Mostrar imagens detectadas\n","print(\"Imagens detectadas (exp_30):\")\n","for img_path in glob.glob('yolov5/runs/detect/test_exp_30/images/*.jpg'):\n","    display(Image(filename=img_path))\n","print(\"Imagens detectadas (exp_60):\")\n","for img_path in glob.glob('yolov5/runs/detect/test_exp_60/images/*.jpg'):\n","    display(Image(filename=img_path))\n","\n","# ===============================\n","# 8️⃣ Treinar CNN do zero\n","# ===============================\n","img_size = (128,128)\n","batch_size = 16\n","\n","train_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(\n","    '/content/FarmTech_Fase6/images/train', target_size=img_size, batch_size=batch_size, class_mode='binary'\n",")\n","val_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(\n","    '/content/FarmTech_Fase6/images/val', target_size=img_size, batch_size=batch_size, class_mode='binary'\n",")\n","test_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(\n","    '/content/FarmTech_Fase6/images/test', target_size=img_size, batch_size=1, class_mode='binary'\n",")\n","\n","model = models.Sequential([\n","    layers.Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)),\n","    layers.MaxPooling2D(2,2),\n","    layers.Conv2D(64, (3,3), activation='relu'),\n","    layers.MaxPooling2D(2,2),\n","    layers.Conv2D(128, (3,3), activation='relu'),\n","    layers.MaxPooling2D(2,2),\n","    layers.Flatten(),\n","    layers.Dense(128, activation='relu'),\n","    layers.Dropout(0.5),\n","    layers.Dense(1, activation='sigmoid')\n","])\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","model.summary()\n","\n","history = model.fit(train_gen, validation_data=val_gen, epochs=30)\n","\n","# ===============================\n","# 9️⃣ Avaliação CNN\n","# ===============================\n","from sklearn.metrics import confusion_matrix, classification_report\n","import numpy as np\n","\n","test_steps = len(test_gen)\n","preds = model.predict(test_gen, steps=test_steps)\n","y_pred = (preds > 0.5).astype(int).reshape(-1)\n","y_true = test_gen.classes\n","\n","print(\"Classification Report:\")\n","print(classification_report(y_true, y_pred, target_names=list(test_gen.class_indices.keys())))\n","\n","cm = confusion_matrix(y_true, y_pred)\n","print(\"Confusion matrix:\\n\", cm)\n"]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","\n","# Caminho da pasta onde o YOLO salva os resultados (ajuste se necessário)\n","result_folder = 'yolov5/runs/train/exp'  # exp, exp2, etc.\n","\n","# Lê os logs do treinamento\n","results_path = os.path.join(result_folder, 'results.csv')\n","results = pd.read_csv(results_path)\n","\n","# Exibe as primeiras linhas para ver o conteúdo\n","print(\"📄 Dados disponíveis no log:\")\n","print(results.head())\n","\n","# Cria os gráficos\n","plt.figure(figsize=(12, 8))\n","\n","plt.subplot(2, 2, 1)\n","plt.plot(results['epoch'], results['train/box_loss'], label='Box Loss')\n","plt.plot(results['epoch'], results['train/obj_loss'], label='Obj Loss')\n","plt.plot(results['epoch'], results['train/cls_loss'], label='Class Loss')\n","plt.title('Treinamento - Perdas')\n","plt.xlabel('Época')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.subplot(2, 2, 2)\n","plt.plot(results['epoch'], results['metrics/precision(B)'], label='Precisão (P)')\n","plt.plot(results['epoch'], results['metrics/recall(B)'], label='Recall (R)')\n","plt.title('Precisão e Recall por Época')\n","plt.xlabel('Época')\n","plt.ylabel('Valor')\n","plt.legend()\n","\n","plt.subplot(2, 2, 3)\n","plt.plot(results['epoch'], results['metrics/mAP50(B)'], label='mAP@50')\n","plt.plot(results['epoch'], results['metrics/mAP50-95(B)'], label='mAP@50-95')\n","plt.title('Desempenho do Modelo (mAP)')\n","plt.xlabel('Época')\n","plt.ylabel('Valor')\n","plt.legend()\n","\n","plt.subplot(2, 2, 4)\n","plt.plot(results['epoch'], results['val/box_loss'], label='Val Box Loss')\n","plt.plot(results['epoch'], results['val/obj_loss'], label='Val Obj Loss')\n","plt.plot(results['epoch'], results['val/cls_loss'], label='Val Cls Loss')\n","plt.title('Validação - Perdas')\n","plt.xlabel('Época')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"CVdFbrtWjple"},"execution_count":null,"outputs":[]}]}