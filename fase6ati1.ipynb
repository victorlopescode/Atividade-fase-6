{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNX5flUA099ONfMt0nsFXP3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"wBHuVdgYvk1P","executionInfo":{"status":"ok","timestamp":1760496285067,"user_tz":180,"elapsed":44181,"user":{"displayName":"Victor Lopes","userId":"09980290957703177404"}},"outputId":"2b8f82e0-a8e2-43b3-db6b-2b9c16e90e95"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 17608, done.\u001b[K\n","remote: Counting objects: 100% (15/15), done.\u001b[K\n","remote: Compressing objects: 100% (13/13), done.\u001b[K\n","remote: Total 17608 (delta 7), reused 2 (delta 2), pack-reused 17593 (from 2)\u001b[K\n","Receiving objects: 100% (17608/17608), 16.82 MiB | 13.58 MiB/s, done.\n","Resolving deltas: 100% (11983/11983), done.\n","/content/yolov5\n","Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (3.1.45)\n","Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (3.10.0)\n","Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (2.0.2)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (4.12.0.88)\n","Requirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (11.3.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (6.0.3)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (2.32.4)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (1.16.2)\n","Collecting thop>=0.1.1 (from -r requirements.txt (line 14))\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (2.8.0+cu126)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (0.23.0+cu126)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (4.67.1)\n","Collecting ultralytics>=8.2.64 (from -r requirements.txt (line 18))\n","  Downloading ultralytics-8.3.214-py3-none-any.whl.metadata (37 kB)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 27)) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 28)) (0.13.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 42)) (25.0)\n","Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 43)) (75.2.0)\n","Requirement already satisfied: urllib3>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 51)) (2.5.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.12)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.9)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.2.5)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.9.0.post0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2025.10.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.15.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.4.0)\n","Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics>=8.2.64->-r requirements.txt (line 18)) (1.25.2)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics>=8.2.64->-r requirements.txt (line 18))\n","  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (3.0.3)\n","Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Downloading ultralytics-8.3.214-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n","Installing collected packages: ultralytics-thop, thop, ultralytics\n","Successfully installed thop-0.1.1.post2209072238 ultralytics-8.3.214 ultralytics-thop-2.0.17\n","Mounted at /content/drive\n"]}],"source":["# Clonar YOLOv5 e instalar dependências\n","!git clone https://github.com/ultralytics/yolov5\n","%cd yolov5\n","!pip install -r requirements.txt\n","\n","# Conectar Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","source":["import os\n","from pathlib import Path\n","\n","# Definir caminhos\n","dataset_base = '/content/drive/MyDrive/FarmTechSolutions'\n","images_path = os.path.join(dataset_base, 'images')\n","labels_path = os.path.join(dataset_base, 'labels')\n","\n","# Criar arquivo data.yaml para YOLO\n","data_yaml = f\"\"\"\n","train: {images_path}/train\n","val: {images_path}/val\n","test: {images_path}/test\n","nc: 2\n","names: ['ObjetoA', 'ObjetoB']\n","\"\"\"\n","\n","with open(f'{dataset_base}/data.yaml', 'w') as f:\n","    f.write(data_yaml)\n","\n","print(\"Arquivo data.yaml criado com sucesso!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OAFCgcL5wBx_","executionInfo":{"status":"ok","timestamp":1760496285852,"user_tz":180,"elapsed":788,"user":{"displayName":"Victor Lopes","userId":"09980290957703177404"}},"outputId":"085552a1-c6b8-4494-ec49-ffaafa0d3fa1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Arquivo data.yaml criado com sucesso!\n"]}]},{"cell_type":"code","source":["# Treinamento 30 épocas\n","!python train.py --img 640 --batch 8 --epochs 30 \\\n","--data /content/drive/MyDrive/FarmTechSolutions/data.yaml \\\n","--weights yolov5s.pt \\\n","--project /content/drive/MyDrive/FarmTechSolutions/results \\\n","--name exp30\n","\n","# Treinamento 60 épocas\n","!python train.py --img 640 --batch 8 --epochs 60 \\\n","--data /content/drive/MyDrive/FarmTechSolutions/data.yaml \\\n","--weights yolov5s.pt \\\n","--project /content/drive/MyDrive/FarmTechSolutions/results \\\n","--name exp60\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"Eh6R-OX_wCWR","outputId":"02545387-a2d2-4b6f-b4dc-50263f261ef5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file ✅ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n","2025-10-15 02:47:38.763869: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1760496458.789412    1375 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1760496458.797268    1375 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1760496458.816435    1375 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1760496458.816491    1375 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1760496458.816497    1375 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1760496458.816501    1375 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n","\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/drive/MyDrive/FarmTechSolutions/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=30, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=/content/drive/MyDrive/FarmTechSolutions/results, name=exp30, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 v7.0-440-gf5ebc52c Python-3.12.12 torch-2.8.0+cu126 CPU\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/FarmTechSolutions/results', view at http://localhost:6006/\n","Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","100% 755k/755k [00:00<00:00, 4.63MB/s]\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n","100% 14.1M/14.1M [00:00<00:00, 41.8MB/s]\n","\n","Overriding model.yaml nc=80 with nc=2\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model summary: 214 layers, 7025023 parameters, 7025023 gradients, 16.0 GFLOPs\n","\n","Transferred 343/349 items from yolov5s.pt\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0m1 validation error for InitSchema\n","size\n","  Field required [type=missing, input_value={'scale': (0.8, 1.0), 'ra...: None, 'strict': False}, input_type=dict]\n","    For further information visit https://errors.pydantic.dev/2.11/v/missing\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/FarmTechSolutions/labels/train... 62 images, 2 backgrounds, 0 corrupt: 100% 64/64 [02:07<00:00,  2.00s/it]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/FarmTechSolutions/labels/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/FarmTechSolutions/labels/val... 4 images, 4 backgrounds, 0 corrupt: 100% 8/8 [00:10<00:00,  1.26s/it]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/FarmTechSolutions/labels/val.cache\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.06 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n","Plotting labels to /content/drive/MyDrive/FarmTechSolutions/results/exp30/labels.jpg... \n","/content/yolov5/train.py:357: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = torch.cuda.amp.GradScaler(enabled=amp)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/content/drive/MyDrive/FarmTechSolutions/results/exp30\u001b[0m\n","Starting training for 30 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","  0% 0/8 [00:00<?, ?it/s]/content/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","       0/29         0G     0.1254    0.02966    0.02415         22        640:  12% 1/8 [00:42<04:59, 42.85s/it]/content/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","       0/29         0G     0.1301    0.02849    0.03778         14        640:  25% 2/8 [01:03<02:58, 29.67s/it]/content/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","       0/29         0G     0.1298    0.02926    0.03658         18        640:  38% 3/8 [01:19<01:58, 23.73s/it]/content/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","       0/29         0G     0.1175    0.02974    0.03232         22        640:  50% 4/8 [01:37<01:24, 21.22s/it]/content/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","       0/29         0G     0.1108    0.02964     0.0295         19        640:  62% 5/8 [01:54<00:59, 19.81s/it]/content/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n"]}]},{"cell_type":"code","source":["from IPython.display import Image, display\n","import glob\n","\n","test_images = glob.glob(f'{images_path}/test/*/*.jpg')  # Ajuste para extensão das suas imagens\n","\n","for img in test_images[:5]:  # mostrar os 5 primeiros\n","    !python detect.py --weights /content/drive/MyDrive/FarmTechSolutions/results/exp60/weights/best.pt \\\n","    --img 640 --source {img} --save-txt --save-conf\n","    display(Image(filename=f'runs/detect/exp/{Path(img).name}'))\n"],"metadata":{"id":"gC36X7zjwCdZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ========================================\n","# ENTREGA 2 – Comparação de Abordagens em Visão Computacional\n","# ========================================\n","\n","# 1️⃣ Configuração inicial\n","!git clone https://github.com/ultralytics/yolov5\n","%cd yolov5\n","!pip install -r requirements.txt\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","from pathlib import Path\n","import glob\n","from IPython.display import Image, display\n","\n","# Caminhos\n","dataset_base = '/content/drive/MyDrive/FarmTechSolutions'\n","images_path = os.path.join(dataset_base, 'images')\n","labels_path = os.path.join(dataset_base, 'labels')\n","results_path = os.path.join(dataset_base, 'results')\n","\n","# Criar data.yaml para YOLO\n","data_yaml = f\"\"\"\n","train: {images_path}/train\n","val: {images_path}/val\n","test: {images_path}/test\n","nc: 2\n","names: ['ObjetoA', 'ObjetoB']\n","\"\"\"\n","with open(f'{dataset_base}/data.yaml', 'w') as f:\n","    f.write(data_yaml)\n","\n","print(\"Arquivo data.yaml criado com sucesso!\")\n","\n","# ========================================\n","# 2️⃣ Treinamento – YOLO customizado (Entrega 1)\n","# ========================================\n","!python train.py --img 640 --batch 8 --epochs 30 \\\n","--data {dataset_base}/data.yaml \\\n","--weights yolov5s.pt \\\n","--project {results_path} \\\n","--name exp30_custom\n","\n","# ========================================\n","# 3️⃣ Treinamento – YOLO padrão\n","# ========================================\n","!python train.py --img 640 --batch 8 --epochs 30 \\\n","--data {dataset_base}/data.yaml \\\n","--weights yolov5s.pt \\\n","--project {results_path} \\\n","--name exp30_standard\n","\n","# ========================================\n","# 4️⃣ Treinamento – CNN do zero\n","# ========================================\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Pré-processamento de imagens\n","train_datagen = ImageDataGenerator(rescale=1./255)\n","val_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    os.path.join(images_path, 'train'),\n","    target_size=(64,64),\n","    batch_size=16,\n","    class_mode='categorical'\n",")\n","\n","val_generator = val_datagen.flow_from_directory(\n","    os.path.join(images_path, 'val'),\n","    target_size=(64,64),\n","    batch_size=16,\n","    class_mode='categorical'\n",")\n","\n","# Construção do modelo CNN\n","model = Sequential([\n","    Conv2D(32, (3,3), activation='relu', input_shape=(64,64,3)),\n","    MaxPooling2D(2,2),\n","    Conv2D(64, (3,3), activation='relu'),\n","    MaxPooling2D(2,2),\n","    Flatten(),\n","    Dense(128, activation='relu'),\n","    Dropout(0.5),\n","    Dense(2, activation='softmax')  # 2 classes\n","])\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","history = model.fit(train_generator, validation_data=val_generator, epochs=20)\n","\n","# Salvar modelo\n","model.save(os.path.join(results_path, 'cnn_from_scratch.h5'))\n","\n","# ========================================\n","# 5️⃣ Inferência e visualização de resultados\n","# ========================================\n","# YOLO customizado e YOLO padrão\n","test_images = glob.glob(f'{images_path}/test/*/*.jpg')\n","\n","for img in test_images[:5]:\n","    !python detect.py --weights {results_path}/exp30_custom/weights/best.pt \\\n","    --img 640 --source {img} --save-txt --save-conf\n","    display(Image(filename=f'runs/detect/exp/{Path(img).name}'))\n","\n","    !python detect.py --weights {results_path}/exp30_standard/weights/best.pt \\\n","    --img 640 --source {img} --save-txt --save-conf\n","    display(Image(filename=f'runs/detect/exp/{Path(img).name}'))\n","\n","# CNN\n","import numpy as np\n","from tensorflow.keras.preprocessing import image\n","\n","for img_path in test_images[:5]:\n","    img_obj = image.load_img(img_path, target_size=(64,64))\n","    x = image.img_to_array(img_obj)/255.0\n","    x = np.expand_dims(x, axis=0)\n","    pred = model.predict(x)\n","    classe = np.argmax(pred)\n","    print(f\"Imagem {Path(img_path).name} - Classe CNN: {classe}\")\n","\n","# ========================================\n","# 6️⃣ Análise crítica (Markdown)\n","# ========================================\n","\n","\"\"\"\n","### Comparação entre abordagens\n","\n","| Critério                     | YOLO Customizado | YOLO Padrão | CNN do Zero |\n","|-------------------------------|----------------|------------|-------------|\n","| Facilidade de uso             | Alta, já adaptada para o dataset | Alta, simples de treinar | Média, precisa de pré-processamento manual |\n","| Precisão do modelo            | Depende do ajuste, geralmente alta | Boa, mas menos específica | Variável, depende da quantidade de dados |\n","| Tempo de treinamento          | Médio (~30-60 epochs) | Médio (~30 epochs) | Médio a alto (depende do tamanho da CNN) |\n","| Tempo de inferência           | Rápido, detecção em objetos múltiplos | Rápido | Médio, apenas classificação única |\n","\n","**Observações:**\n","- A YOLO customizada geralmente se adapta melhor ao dataset específico.\n","- A YOLO padrão funciona bem “out-of-the-box”, mas pode ter limitações em casos específicos.\n","- A CNN do zero é interessante para classificação simples, mas não realiza detecção de múltiplos objetos na mesma imagem.\n","\"\"\"\n","\n"],"metadata":{"id":"5RUuenQCwCjz"},"execution_count":null,"outputs":[]}]}